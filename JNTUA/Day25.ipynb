{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy\n",
    "correct_values = 90\n",
    "total_values = 100\n",
    "accuracy = (correct_values / total_values) * 100\n",
    "print(f'Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for missing values\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Name': ['Aishwarya', 'Rahul', None], 'Age': [25, None, 30]})\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"Missing Value Percentage:\")\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Consistency Check Example\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['Arjun', 'Priya']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2], 'Name': ['Arjun', 'Divya']})\n",
    "inconsistent_data = df1.merge(df2, on='ID', suffixes=('_df1', '_df2'))\n",
    "print(\"\\nInconsistent Data:\")\n",
    "print(inconsistent_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate timeliness\n",
    "from datetime import datetime\n",
    "\n",
    "data_timestamp = datetime(2023, 10, 15)  # Example timestamp\n",
    "current_time = datetime.now()\n",
    "timeliness = (current_time - data_timestamp).days\n",
    "print(f'\\nData is {timeliness} days old.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for duplicate records\n",
    "df = pd.DataFrame({'ID': [1, 2, 2, 3]})\n",
    "duplicates = df[df.duplicated()]\n",
    "print(\"\\nDuplicate Records:\")\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Validity Check Example\n",
    "import re\n",
    "\n",
    "emails = ['ravi@example.com', 'invalid-email', 'geetha@domain.org', 'invalid@.com.']\n",
    "valid_emails = [email for email in emails if re.match(r'^[\\w.-]+@[\\w.-]+\\.\\w+$', email)]\n",
    "print(\"\\nValid Emails:\")\n",
    "print(valid_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Consistency Check Example\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['John', 'Jane']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2], 'Name': ['John', 'Doe']})\n",
    "inconsistent_data = df1.merge(df2, on='ID', suffixes=('df1', 'df2'))\n",
    "print(inconsistent_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrames with potential inconsistencies in product prices\n",
    "df_inventory = pd.DataFrame({\n",
    "    'product_id': [101, 102, 103, 104],\n",
    "    'product_name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor'],\n",
    "    'inventory_price': [1200.00, 25.00, 50.00, 300.00]\n",
    "})\n",
    "\n",
    "df_sales = pd.DataFrame({\n",
    "    'product_id': [101, 102, 103, 104],\n",
    "    'product_name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor'],\n",
    "    'sales_price': [1200.00, 25.00, 55.00, 300.00]\n",
    "})\n",
    "\n",
    "# Merge DataFrames to find price discrepancies\n",
    "price_inconsistencies = pd.merge(df_inventory, df_sales, on='product_id', suffixes=('_inventory', '_sales'))\n",
    "\n",
    "# Filter to show only rows where prices differ\n",
    "price_inconsistencies = price_inconsistencies[price_inconsistencies['inventory_price'] != price_inconsistencies['sales_price']]\n",
    "\n",
    "print(\"Price Inconsistencies:\")\n",
    "print(price_inconsistencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Sample DataFrame for all checks\n",
    "data = {\n",
    "    'ID': [1, 2, 2, 3, 4, 5],\n",
    "    'Name': ['Aishwarya', 'Rahul', 'Rahul', 'Priya', None, 'Geetha'],\n",
    "    'Age': [25, None, None, 30, 28, 35],\n",
    "    'Email': ['aishwarya@example.com', 'invalid-email', 'rahul@domain.org', 'priya@example.in', 'test@.com.', 'geetha@domain.org'],\n",
    "    'Timestamp': ['2023-10-15', '2023-10-16', '2023-10-15', '2023-10-17', '2023-10-18', '2023-10-19'],\n",
    "    'Confirmation': [True, False, True, True, False, True] # Example Confirmation Column\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Check for missing values\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"Missing Value Percentage:\")\n",
    "print(missing_percentage)\n",
    "\n",
    "# 2. Consistency Check (checking for duplicate names, for example)\n",
    "duplicate_names = df[df.duplicated(subset=['Name'], keep=False)]\n",
    "print(\"\\nDuplicate Names:\")\n",
    "print(duplicate_names)\n",
    "\n",
    "# 3. Calculate timeliness (using the 'Timestamp' column)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "current_time = datetime.now()\n",
    "timeliness = (current_time - df['Timestamp'].max()).days\n",
    "print(f'\\nData is at most {timeliness} days old.')\n",
    "\n",
    "# 4. Check for duplicate records (using the 'ID' column)\n",
    "duplicates = df[df.duplicated(subset=['ID'])]\n",
    "print(\"\\nDuplicate IDs:\")\n",
    "print(duplicates)\n",
    "\n",
    "# 5. Validity Check (checking email validity)\n",
    "valid_emails = [email for email in df['Email'] if re.match(r'^[\\w.-]+@[\\w.-]+\\.\\w+$', email)]\n",
    "print(\"\\nValid Emails:\")\n",
    "print(valid_emails)\n",
    "\n",
    "#6. Calculate Accuracy based on the 'Confirmation' column\n",
    "correct_values = df['Confirmation'].sum()\n",
    "total_values = len(df)\n",
    "accuracy = (correct_values / total_values) * 100\n",
    "print(f'\\nAccuracy (Confirmation): {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Sample DataFrame for all checks\n",
    "data = {\n",
    "    'ID': [1, 2, 2, 3, 4, 5],\n",
    "    'Name': ['Aishwarya', 'Rahul', 'Rahul', 'Priya', None, 'Geetha'],\n",
    "    'Age': [25, None, None, 30, 28, 35],\n",
    "    'Email': ['aishwarya@example.com', 'invalid-email', 'rahul@domain.org', 'priya@example.in', 'test@.com.', 'geetha@domain.org'],\n",
    "    'Timestamp': ['2023-10-15', '2023-10-16', '2023-10-15', '2023-10-17', '2023-10-18', '2023-10-19']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize Confirmation column with False\n",
    "df['Confirmation'] = False\n",
    "\n",
    "# 1. Check for missing values and update Confirmation\n",
    "df.loc[df['Name'].notnull() & df['Age'].notnull(), 'Confirmation'] = True\n",
    "print(\"Missing Value Check Done.\")\n",
    "\n",
    "# 2. Consistency Check (checking for duplicate names) and update Confirmation\n",
    "df.loc[~df.duplicated(subset=['Name'], keep=False), 'Confirmation'] = True\n",
    "print(\"\\nConsistency Check Done.\")\n",
    "\n",
    "# 3. Calculate timeliness (using the 'Timestamp' column)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "current_time = datetime.now()\n",
    "timeliness = (current_time - df['Timestamp'].max()).days\n",
    "print(f'\\nData is at most {timeliness} days old.')\n",
    "\n",
    "# 4. Check for duplicate records (using the 'ID' column) and update Confirmation\n",
    "df.loc[~df.duplicated(subset=['ID']), 'Confirmation'] = True\n",
    "print(\"\\nDuplicate ID Check Done.\")\n",
    "\n",
    "# 5. Validity Check (checking email validity) and update Confirmation\n",
    "df['Valid_Email'] = df['Email'].apply(lambda email: bool(re.match(r'^[\\w.-]+@[\\w.-]+\\.\\w+$', email)))\n",
    "df.loc[df['Valid_Email'] == True, 'Confirmation'] = True\n",
    "print(\"\\nEmail Validity Check Done.\")\n",
    "\n",
    "# 6. Calculate Accuracy based on the updated 'Confirmation' column\n",
    "correct_values = df['Confirmation'].sum()\n",
    "total_values = len(df)\n",
    "accuracy = (correct_values / total_values) * 100\n",
    "print(f'\\nAccuracy (Post-Checks): {accuracy}%')\n",
    "\n",
    "# Display the dataframe with the confirmation column.\n",
    "print(\"\\nDataframe with Confirmation Column\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data quality scores\n",
    "data = {'Dimension': ['Accuracy', 'Completeness', 'Consistency', 'Timeliness', 'Validity'],\n",
    "        'Score': [90, 85, 80, 95, 88]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting a bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(df['Dimension'], df['Score'], color='skyblue')\n",
    "plt.xlabel('Data Quality Dimension')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.title('Data Quality Scores by Dimension')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Entries': [1, 2, 3, 4, None, 6, 7, None, 9, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "errors = df['Entries'].isnull().sum()\n",
    "total_entries = df['Entries'].count() + errors\n",
    "valid_entries = total_entries - errors\n",
    "DQI = (valid_entries - errors) * 100 / total_entries\n",
    "print(\"Counted Errors:\", errors)\n",
    "print(\"DQI with counted errors:\", DQI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "df_ge = ge.from_pandas(df)\n",
    "df_ge.expect_column_values_to_not_be_null('Email')\n",
    "df_ge.expect_column_values_to_match_regex('Email', r\".+@.+\\..+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: Warning: Numpy built with MINGW-W64 on Windows 64 bits is experimental, and only available for \n",
      "testing. You are advised not to use it for production. \n",
      "\n",
      "CRASHES ARE TO BE EXPECTED - PLEASE REPORT THEM TO NUMPY DEVELOPERS\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Pandera version:\", pa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"success\": false,\n",
    "    \"results\": [\n",
    "        {\n",
    "            \"success\": false,\n",
    "            \"expectation_config\": {\n",
    "                \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
    "                \"kwargs\": {\n",
    "                    \"column\": \"Name\"\n",
    "                }\n",
    "            },\n",
    "            \"result\": {\n",
    "                \"element_count\": 3,\n",
    "                \"unexpected_count\": 1,\n",
    "                \"unexpected_percent\": 33.333333333333336,\n",
    "                \"unexpected_percent_total\": 33.333333333333336,\n",
    "                \"unexpected_percent_nonmissing\": 33.333333333333336,\n",
    "                \"partial_unexpected_list\": [null]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"success\": true,\n",
    "            \"expectation_config\": {\n",
    "                \"expectation_type\": \"expect_column_values_to_be_between\",\n",
    "                \"kwargs\": {\n",
    "                    \"column\": \"Age\",\n",
    "                    \"min_value\": 0,\n",
    "                    \"max_value\": 100\n",
    "                }\n",
    "            },\n",
    "            \"result\": {\n",
    "                \"element_count\": 3,\n",
    "                \"unexpected_count\": 1,\n",
    "                \"unexpected_percent\": 33.333333333333336,\n",
    "                \"unexpected_percent_total\": 33.333333333333336,\n",
    "                \"unexpected_percent_nonmissing\": 50.0,\n",
    "                \"partial_unexpected_list\": [None]\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"statistics\": {\n",
    "        \"evaluated_expectations\": 2,\n",
    "        \"successful_expectations\": 1,\n",
    "        \"unsuccessful_expectations\": 1,\n",
    "        \"success_percent\": 50.0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: Warning: Numpy built with MINGW-W64 on Windows 64 bits is experimental, and only available for \n",
      "testing. You are advised not to use it for production. \n",
      "\n",
      "CRASHES ARE TO BE EXPECTED - PLEASE REPORT THEM TO NUMPY DEVELOPERS\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera import Column, Check\n",
    "\n",
    "# Sample data\n",
    "data = {'Name': ['John', 'Jane', None], 'Age': [25, None, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define Pandera schema\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"Name\": Column(str, nullable=False, checks=Check.not_null()),\n",
    "    \"Age\": Column(float, nullable=True, checks=Check.in_range(0, 100, include_min=True, include_max=True)),\n",
    "})\n",
    "\n",
    "try:\n",
    "    # Validate the DataFrame against the schema\n",
    "    validated_df = schema(df)\n",
    "    print(\"Validation successful!\")\n",
    "    print(validated_df)\n",
    "\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(\"Validation failed:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Sample data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJohn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJane\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDoe\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m30\u001b[39m]}\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "# pip install ydata-profiling\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# Sample data\n",
    "data = {'Name': ['John', 'Jane', 'Doe'], 'Age': [25, None, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate a data profiling report\n",
    "profile = ProfileReport(df, title='Data Quality Report', explorative=True)\n",
    "profile.to_file('data_quality_report.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the problem statement formatted for display on a **projector** and the **SQL query** in Jupyter Notebook **Markdown**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Projector Display: Problem Statement**  \n",
    "\n",
    "# **📌 Student Grades Normalization at Dheeraj Engineering College**  \n",
    "\n",
    "### **Scenario**  \n",
    "At **Dheeraj Engineering College**, professors use different grading systems to evaluate students:  \n",
    "✅ **Percentage (0-100%)**  \n",
    "✅ **GPA (0-4 scale)**  \n",
    "✅ **Letter Grades (A, B, C, etc.)**  \n",
    "\n",
    "The **administration** needs a standardized grading system (0-100%) for fair comparisons.  \n",
    "\n",
    "As a **data analyst**, your task is to:  \n",
    "🔹 Normalize student grades into **percentage format**  \n",
    "🔹 Identify **top performers**  \n",
    "🔹 Detect **at-risk students (<40%)**  \n",
    "🔹 Use **Excel, SQL, or Python** for analysis  \n",
    "\n",
    "---\n",
    "\n",
    "### **Grading Conversion Rules**  \n",
    "\n",
    "| Grade Type  | Conversion Formula |\n",
    "|------------|--------------------|\n",
    "| **Percentage** | No change |\n",
    "| **GPA (4.0 scale)** | Multiply by 25 (e.g., **3.2 GPA → 80%**) |\n",
    "| **Letter Grades** | Convert using this mapping:  |\n",
    "| **A+ → 95%** | **A → 93%** | **B+ → 87%** |  \n",
    "| **B → 83%** | **C+ → 78%** | **C → 73%** |  \n",
    "| **D → 65%** | **F → 35%** |  \n",
    "\n",
    "---\n",
    "\n",
    "### **Dataset: Student Grades at Dheeraj Engineering College**  \n",
    "\n",
    "| Student ID | Name      | Subject   | Grade Type  | Original Grade |\n",
    "|-----------|-----------|-----------|------------|---------------|\n",
    "| 201       | Aarav     | Math      | Percentage | 78            |\n",
    "| 202       | Ishita    | Physics   | GPA        | 3.2           |\n",
    "| 203       | Rajesh    | Chemistry | Letter     | B+            |\n",
    "| 204       | Priya     | Biology   | Percentage | 88            |\n",
    "| 205       | Manish    | Math      | GPA        | 2.8           |\n",
    "| 206       | Riya      | Physics   | Letter     | C             |\n",
    "| 207       | Vikram    | Chemistry | Percentage | 93            |\n",
    "| 208       | Sanya     | Biology   | GPA        | 3.6           |\n",
    "| 209       | Harsh     | Math      | Letter     | A             |\n",
    "| 210       | Neha      | Physics   | Percentage | 52            |\n",
    "\n",
    "---\n",
    "\n",
    "### **Tasks for You**\n",
    "💡 Use **Excel, SQL, or Python** to:\n",
    "1️⃣ **Normalize the dataset**  \n",
    "2️⃣ **Find students scoring below 40%**  \n",
    "3️⃣ **Identify top 3 performers**  \n",
    "4️⃣ **Visualize student performance**  \n",
    "\n",
    "---\n",
    "\n",
    "## **SQL Query for Normalization (Jupyter Notebook Markdown)**  \n",
    "```sql\n",
    "-- Create the student grades table\n",
    "CREATE TABLE StudentGrades (\n",
    "    Student_ID INT PRIMARY KEY,\n",
    "    Name VARCHAR(50),\n",
    "    Subject VARCHAR(50),\n",
    "    Grade_Type VARCHAR(20),\n",
    "    Original_Grade VARCHAR(10)\n",
    ");\n",
    "\n",
    "-- Insert data into the table\n",
    "INSERT INTO StudentGrades (Student_ID, Name, Subject, Grade_Type, Original_Grade) VALUES\n",
    "(201, 'Aarav', 'Math', 'Percentage', '78'),\n",
    "(202, 'Ishita', 'Physics', 'GPA', '3.2'),\n",
    "(203, 'Rajesh', 'Chemistry', 'Letter', 'B+'),\n",
    "(204, 'Priya', 'Biology', 'Percentage', '88'),\n",
    "(205, 'Manish', 'Math', 'GPA', '2.8'),\n",
    "(206, 'Riya', 'Physics', 'Letter', 'C'),\n",
    "(207, 'Vikram', 'Chemistry', 'Percentage', '93'),\n",
    "(208, 'Sanya', 'Biology', 'GPA', '3.6'),\n",
    "(209, 'Harsh', 'Math', 'Letter', 'A'),\n",
    "(210, 'Neha', 'Physics', 'Percentage', '52');\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
